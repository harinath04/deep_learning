{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0200e82a",
      "metadata": {
        "id": "0200e82a",
        "outputId": "e2647500-cc07-44c8-f0cc-609ddb6c748d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2005282968.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSerpAPIWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import operator\n",
        "from typing import TypedDict, Annotated, List\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "from langgraph.graph import StateGraph, END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "389f99ee",
      "metadata": {
        "id": "389f99ee"
      },
      "outputs": [],
      "source": [
        "os.environ[\"SERPAPI_API_KEY\"] = \"dbb3d3230a3ad966b1f2d71005587f47707364ca72f80cd040534a523451094d\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    api_key=\"not-needed\",\n",
        "    base_url=\"http://localhost:1234/v1\",\n",
        "    model=\"local-model\",\n",
        "    temperature=0,\n",
        "    streaming=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2891b362",
      "metadata": {
        "id": "2891b362"
      },
      "outputs": [],
      "source": [
        "# --- Tool Definition ---\n",
        "# Instantiate the SerpAPI search tool.\n",
        "search_tool = SerpAPIWrapper()\n",
        "\n",
        "# --- State Definition ---\n",
        "# This defines the \"memory\" or \"state\" that flows through the graph.\n",
        "class ResearchState(TypedDict):\n",
        "    topic: str\n",
        "    explanation: str\n",
        "    summary: str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc97a34",
      "metadata": {
        "id": "6dc97a34"
      },
      "outputs": [],
      "source": [
        "def researcher_agent(state: ResearchState) -> dict:\n",
        "    \"\"\"\n",
        "    This agent uses a web search tool to find information on a topic and then explains it.\n",
        "    \"\"\"\n",
        "    print(\"---RESEARCHER (with SerpApi Web Search)---\")\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    # Use the tool to search for information. The .run() method takes the query string.\n",
        "    search_results = search_tool.run(topic)\n",
        "\n",
        "    print(f\"Search Results:\\n{search_results}\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"You are a helpful research assistant. Based on the following search results,\n",
        "        provide a brief, easy-to-understand explanation of the topic: {topic}.\n",
        "\n",
        "        Search Results:\n",
        "        {search_results}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"topic\": topic, \"search_results\": search_results})\n",
        "\n",
        "    print(f\"Researcher's Explanation:\\n{result.content}\")\n",
        "    return {\"explanation\": result.content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d137f518",
      "metadata": {
        "id": "d137f518"
      },
      "outputs": [],
      "source": [
        "def summarizer_agent(state: ResearchState) -> dict:\n",
        "    \"\"\"\n",
        "    This agent takes an explanation and summarizes it in one sentence.\n",
        "    \"\"\"\n",
        "    print(\"---SUMMARIZER---\")\n",
        "    explanation = state[\"explanation\"]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"You are a summarization expert. Condense the following text into a single, concise sentence:\\n\\n{explanation}\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"explanation\": explanation})\n",
        "\n",
        "    print(f\"Summarizer's Output:\\n{result.content}\")\n",
        "    return {\"summary\": result.content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d37079",
      "metadata": {
        "id": "67d37079"
      },
      "outputs": [],
      "source": [
        "# --- Graph Definition ---\n",
        "\n",
        "workflow = StateGraph(ResearchState)\n",
        "\n",
        "# Add the agent functions as nodes\n",
        "workflow.add_node(\"researcher\", researcher_agent)\n",
        "workflow.add_node(\"summarizer\", summarizer_agent)\n",
        "\n",
        "# Define the edges, which control the flow\n",
        "workflow.add_edge(\"researcher\", \"summarizer\")\n",
        "workflow.add_edge(\"summarizer\", END)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"researcher\")\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adbe03ed",
      "metadata": {
        "id": "adbe03ed"
      },
      "outputs": [],
      "source": [
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    topic = input(\"Please enter a topic for the agents to research and summarize: \")\n",
        "\n",
        "    inputs = {\"topic\": topic}\n",
        "    final_state = app.invoke(inputs)\n",
        "\n",
        "    print(\"\\n--- FINAL SUMMARY ---\")\n",
        "    print(final_state['summary'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "agents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}